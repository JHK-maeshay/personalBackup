{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4-11-logistic-regression.ipynb","provenance":[],"authorship_tag":"ABX9TyNaVPB1DQjen9iyv8yjCbSU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["+ **로지스틱 회귀 모델의 확률추정(벡터 표현식)**\n","\n","로지스틱 회귀는 결과값의 로지스틱(logistic)을 출력합니다\n","\n","$$\\hat{\\rho}=h_\\theta(\\mathbf{x})=\\sigma (\\theta^T\\mathbf{x} )$$\n","\n","***\n","**선형 회귀 모델(벡터): $\\hat{y} = h_\\boldsymbol{\\theta}(x) = \\boldsymbol{\\theta}  \\boldsymbol{\\cdot} x$\n","***"],"metadata":{"id":"Sb5-UKPPnBj3"}},{"cell_type":"markdown","source":["로지스틱 함수는 0과 1 사의 값을 출력하는 함수입니다.\n","+ 로지스틱 (Sigmoid) 함수\n","$\\sigma(t)=\\frac{1}{1+exp(-t)} $\n","\n","**참고\n","\n","+ tanh 함수\n","$\\sigma(t)=tanh(x)=\\frac{exp(t)-exp(-t)}{exp(t)+exp(-t)} $\n","\n","+ ReLU 함수\n","$\\sigma(t)=\\begin{cases} x & (x\\gt0) \\\\ 0 & (x<0) \\end{cases}$"],"metadata":{"id":"NrNTSikgnnhd"}},{"cell_type":"markdown","source":["+ 로지스틱 회귀 모델 예측\n","\n","$\n","\\hat{y} =\n","\\begin{cases}\n","  0 & (\\hat{p} < 0.5) \\\\\n","  1 & (\\hat{p} > 0.5)\n","\\end{cases}\n","$\n","\n","t < 0이면 $\\sigma(t)$ < 0.5이고, $t\\geq0$이면  $\\sigma(t) \\geq 0.5$이므로 로지스틱 회귀 모델은 $\\mathbf{\\theta}^T\\textbf{x}$ 가 양수 일때 1 (양성 클래스) 이라고 예측하고, 음수일 때 0 (음성 클래스)이라고 예측합니다."],"metadata":{"id":"UGYPxP1RpfMR"}},{"cell_type":"markdown","source":["***\n","1. 선형 회귀의 비용 함수\n","$$J(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}\\frac{1}{2}(h_\\theta(x^{(i)}-y^{(i)}))^2\n","$$\n","\n","2. 로지스틱 회귀의 비용 함수\n","$$J(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}Cost(h_\\theta(x^{(i)}),y^{(i)})\n","$$\n","\n","$$when$$\n","\n","$$Cost(h_\\theta(x^{(i)}),y^{(i)}) = \\frac{1}{2}(h_\\theta(x^{(i)}-y^{(i)}))^2\n","$$\n","\n","3. 경사하강법에 적용하기 위해 convex함수로 변환\n","$$Cost(h_\\theta(x^{(i)}),y^{(i)}) = \\begin{cases} -log(h_\\theta(x)) & (y=1) \\\\ -log(1-h_\\theta(x)) & (y=0) \\end{cases}\n","$$\n","$$mean$$\n","$$y=1 \\text{ and } h_\\theta(x)=1 → cost = 0$$\n","$$y=0 \\text{ and } h_\\theta(x)=0 → cost = 0$$\n","\n","4. 비용 함수에 적용\n","\n","$$\\begin{cases} Cost =  y^{(i)}log(h_\\theta(\\mathbf{x})) & (y=1) \\\\ Cost = (1 - y^{(i)}) log(1 - h_\\theta(\\mathbf{x})) & (y=0) \\end{cases}\n","$$\n","\n","$$\n","J(\\boldsymbol{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(h_\\theta(\\mathbf{x})\\right) + (1 - y^{(i)}) log\\left(1 - h_\\theta(\\mathbf{x})\\right)\\right]}\n","$$\n","\n","**1/2이 생략됨\n","***"],"metadata":{"id":"8flE5oZDwYCl"}},{"cell_type":"markdown","source":["***\n","**참고,,,\n","\n","$\\sigma(t)=\\frac{1}{1+exp(-t)} $ 에게는\n","$\\frac{d}{dt}\\sigma=\\sigma-\\sigma^2 $라는 성질이 있어요...\n","***"],"metadata":{"id":"v0q4TQUl8faY"}},{"cell_type":"markdown","source":["5. 로지스틱 비용 함수의 편도 함수**\n","\n","$$\n","\\dfrac{\\partial}{\\partial \\theta_j} \\text{J}(\\boldsymbol{\\theta}) = \\dfrac{1}{m}\\sum\\limits_{i=1}^{m}\\left(\\mathbf{\\sigma(\\boldsymbol{\\theta}}^T \\mathbf{x}^{(i)}) - y^{(i)}\\right)\\, x_j^{(i)}\n","$$\n","+ $x_j$는 $\\theta_j$에 해당하는 x입니다."],"metadata":{"id":"YBib6yvssisp"}}]}