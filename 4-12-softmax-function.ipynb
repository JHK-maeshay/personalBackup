{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4-12-softmax-function.ipynb","provenance":[],"authorship_tag":"ABX9TyPLyPw2k13NyEz0naZvA5iU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["샘플 $\\mathbf{x}$가 주어지면 먼저 소프트맥스 회귀 모델이 각 클래스 $k$에 대한 점수 $s_k(\\mathbf{x})$를 계산합니다.\n","\n","$s_k(\\mathbf{x})$에 소프트맥스 함수(softmax function) 또는 정규화된 지수 함수(normalized exponential function)를 적용하여 각 클래스의 확률을 추정합니다.\n","\n","+ **클래스 $k$에 대한 소프트맥수 점수**\n","\n","$$s_k(\\mathbf{x}) = (\\theta^{(k)})^T\\mathbf{x}$$\n","\n","각 클래스는 자신만의 파라미터 벡터 $\\theta^{(k)}$가 있습니다. 이 벡터들은 parameter matrix,\n","\n","$\\Theta$에 행으로 저장됩니다."],"metadata":{"id":"C1XED_Sgjmsq"}},{"cell_type":"markdown","source":["+ **소프트맥스 함수**\n","\n","$$\n","\\hat{p}_k = \\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k = \\dfrac{\\exp\\left(s_k(\\mathbf{x})\\right)}{\\sum\\limits_{j=1}^{K}{\\exp\\left(s_j(\\mathbf{x})\\right)}}\n","$$\n","\n","*   $K$는 클래스 입니다. \n","*   $\\mathbf{s}(\\mathbf{x})$는 샘플 $\\mathbf{x}$에 대한 각 클래스의 점수를 담은 벡터입니다. \n","*   $\\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k$는 샘플 $\\mathbf{x}$에 대한 각 클래스의 점수가 주어졌을 때 이 샘플의 클래스 $k$에 속할 추정 확률 입니다.\n","\n","***\n","**참고 간략한 형태\n","\n","$$y_k=\\frac{e^{ak}}{\\sum_{i=1}^{n}e^{ai}}\n","$$\n","***"],"metadata":{"id":"3FuKFWtmko2W"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"3tfUqGT1mXHF"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"dA9gUUs2m7A5"}},{"cell_type":"markdown","source":["+ **소프트맥스 회귀 분류기의 예측**\n","\n","$$\\hat{y} = \\underset{k}{\\textbf{argmax}}(\\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k) = \\underset{k}{\\textbf{argmax}}(\\mathbf{s_k}(\\mathbf{x})) = \\underset{k}{\\textbf{argmax}}((\\mathbf{\\theta^{(k)})^T}\\mathbf{x})$$\n","\n","argmax 연산은 함수를 최대화하는 변수의 값을 반환합니다. 이식에서는 추정 확률 $\\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k$가 최대인 $k$값을 반환합니다."],"metadata":{"id":"hNi6ruwylIOM"}},{"cell_type":"markdown","source":["+ **Cross-Entropy**\n","$$H(p, q) = -\\sum_{i}^{m}  p_ilog_2(q_i)$$\n","\n","+ $p$는 참값입니다\n","+ $q$는 예측값입니다\n","\n","***\n","**참고 $log_2(x)=log(x)/log(2)$\n","***"],"metadata":{"id":"6B3vtWULlep_"}},{"cell_type":"markdown","source":["+ **크로스 엔트로피 비용 함수**\n","\n","$$\n","J(\\boldsymbol{\\Theta}) = - \\dfrac{1}{m}\\sum\\limits_{i=1}^{m}\\sum\\limits_{k=1}^{K}{y_k^{(i)}\\log\\left(\\hat{p}_k^{(i)}\\right)}\n","$$\n","\n","* 이 식에서는 $y_k^{(i)}$는 $i$번째 샘플이 클래스 $k$에 속할 타킷 확률입니다. 일반적으로 샘플이 클래스에 속하는지 아닌지에 따라 1 도는 0이 됩니다. "],"metadata":{"id":"H199ri1inAVX"}},{"cell_type":"markdown","source":["***\n","****헷갈리지 마세요**\n","\n","$s_k(\\mathbf{x}) = (\\theta^{(k)})^T\\mathbf{x}$에서, \n","$\\theta^{(k)}$는 각 class의 parameter 열벡터를 나타냅니다.\n","***"],"metadata":{"id":"MlNZqFZGtKoA"}}]}